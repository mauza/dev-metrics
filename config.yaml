llm:
  provider: "openai"
  endpoint: "https://ollama.mau.guru/api/chat/completions"
  model: "qwq:latest"
  max_tokens: 2000
  api_key_env_var: "OPENAI_API_KEY"
  temperature: 0.7
repositories:
- path: ../skoop
  patterns:
  - '*.py'
  - '*.js'
  - '*.ts'
  - '*.md'
  - '*.yaml'
  - '*.json'
